import os
import openai
import torch
import whisper
from dotenv import load_dotenv
from docx import Document

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# âœ… macOS ë‹¤ìš´ë¡œë“œ í´ë” ì„¤ì •
download_path = os.path.join(os.path.expanduser('~'), 'Downloads')

# âœ… GPU ì§€ì› ì—¬ë¶€ í™•ì¸
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ğŸ–¥ Using device: {device}")

# âœ… Whisper ëª¨ë¸ ë¡œë“œ
model = whisper.load_model("medium").to(device)
print("Whisper model loaded successfully!")

def download_youtube_audio(youtube_link, output_format='mp3'):
    """ YouTube ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ë° ë³€í™˜ """
    command = f'yt-dlp -x --audio-format {output_format} -o "{download_path}/%(title)s.{output_format}" {youtube_link}'
    print(f"Executing command: {command}")
    
    result = os.system(command)
    if result == 0:
        # ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ëª… í™•ì¸
        files = [f for f in os.listdir(download_path) if f.endswith(f".{output_format}")]
        if files:
            audio_file = os.path.join(download_path, files[-1])  # ìµœì‹  íŒŒì¼ ë°˜í™˜
            print(f"âœ… ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {audio_file}")
            return audio_file
        else:
            print("âŒ ë‹¤ìš´ë¡œë“œëœ MP3 íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
    else:
        print("âŒ ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ë° ë³€í™˜ ì‹¤íŒ¨")
        return None

def transcribe_and_translate(audio_path):
    """ Whisperë¥¼ ì´ìš©í•œ ì˜¤ë””ì˜¤ ì „ì‚¬ ë° OpenAI API ë²ˆì—­ """
    print(f"ğŸ¤ Transcribing audio file: {audio_path}")

    if not os.path.exists(audio_path):
        print("âŒ Audio file not found, skipping transcription.")
        return None, None

    try:
        print("âš¡ Whisper ëª¨ë¸ì´ ì „ì‚¬ ì¤‘... (ì´ ê³¼ì •ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŒ)")
        transcript = model.transcribe(audio_path, language="ja", initial_prompt="æ—¥æœ¬èªã®éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã—ã¦ãã ã•ã„ã€‚")
        print("âœ… ì „ì‚¬ ì™„ë£Œ!") 

        print(f"ğŸ“ Whisper Output: {transcript}")  

        japanese_transcript = [
            {"start": segment["start"], "end": segment["end"], "text": segment["text"]}
            for segment in transcript["segments"] if segment["text"]
        ]
        print(f"ğŸ“œ Extracted Japanese Transcript: {japanese_transcript}")

        summary, translated_entries = summarize_and_translate(japanese_transcript)
        return summary, translated_entries

    except Exception as e:
        print("âŒ Whisper ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)
        return None, None

def summarize_and_translate(transcript_data):
    """ OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì¼ë³¸ì–´ í…ìŠ¤íŠ¸ ìš”ì•½ ë° ë²ˆì—­ """
    openai.api_key = os.getenv("OPENAI_API_KEY")
    if not transcript_data:
        print("âŒ No transcript data found for translation.")
        return None, None

    full_text = " ".join([entry["text"] for entry in transcript_data])

    try:
        print("ğŸ“¢ Sending text to OpenAI API for summarization...")
        summary_response = openai.Completion.create(
            engine="davinci",
            prompt=f"Summarize this Japanese text: '{full_text}'",
            max_tokens=150
        )
        summary = summary_response.choices[0].text.strip()
        print(f"ğŸ“ Summary: {summary}")

        translated_entries = []
        for entry in transcript_data:
            print(f"ğŸ“¢ Sending text to OpenAI API for translation: {entry['text']}")
            translation_response = openai.Completion.create(
                engine="davinci",
                prompt=f"Translate this Japanese text into Korean: '{entry['text']}'",
                max_tokens=150
            )
            translated_text = translation_response.choices[0].text.strip()
            print(f"âœ… Translated: {translated_text}")

            translated_entries.append({
                "start": entry["start"],
                "end": entry["end"],
                "japanese": entry["text"],
                "korean": translated_text
            })

        return summary, translated_entries
    except Exception as e:
        print("âŒ OpenAI API ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)
        return None, None

def save_transcript_to_docx(summary, translated_data, output_filename="translated_transcript.docx"):
    """ ë²ˆì—­ëœ ë‚´ìš©ì„ DOCX íŒŒì¼ë¡œ ì €ì¥ """
    output_path = os.path.join(download_path, output_filename)
    print(f"ğŸ“‚ Saving translated document to: {output_path}")

    doc = Document()
    doc.add_heading('Summary', level=1)
    doc.add_paragraph(summary)
    doc.add_page_break()

    doc.add_heading('Translations', level=1)
    for entry in translated_data:
        doc.add_paragraph(f"[{entry['start']}s - {entry['end']}s]", style="Heading 3")
        doc.add_paragraph(entry["japanese"], style="Normal")
        doc.add_paragraph(entry["korean"], style="Normal")
        doc.add_paragraph("")

    doc.save(output_path)
    print(f"âœ… Translated document saved successfully at: {output_path}")

if __name__ == "__main__":
    youtube_link = input("Please enter the YouTube link: ").strip()
    if youtube_link:
        audio_path = download_youtube_audio(youtube_link)
        print(f"Received audio file: {audio_path}")

        if audio_path and os.path.exists(audio_path):
            print("âœ… Starting transcription and translation...")
            summary, translated_transcript = transcribe_and_translate(audio_path)

            if summary and translated_transcript:
                save_transcript_to_docx(summary, translated_transcript, "translated_transcript.docx")
            else:
                print("âŒ Translation or transcription failed.")
        else:
            print("âŒ Audio download failed or file not found.")
    else:
        print("âŒ No YouTube link provided.")
